{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning\n",
    "\n",
    "We want to build a predictive model to predict whether or not a flight will be delayed based on several different parameters. Rather than collect weather data for every airport in our dataset, we will only be using the data from the following cities:\n",
    "* LA\n",
    "* Chicago\n",
    "* Boston\n",
    "* Phoenix\n",
    "* Denver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Two helper functions that will be used later\n",
    "\n",
    "# Round a date to the nearest hour, then convert it to a datetime object\n",
    "def round_date(year, month, day, time):\n",
    "    return dt.datetime(int(year), int(month), int(day), int(time[:2]))\n",
    "\n",
    "# Round a time to the nearest 15 min, then convert it to a time object\n",
    "def round_quarter_hour(timestr):\n",
    "    hour = int(timestr[:2])\n",
    "    minute = int(timestr[2:])\n",
    "    if minute < 7.5:\n",
    "        minute = 0\n",
    "    elif minute >= 7.5 and minute < 22.5:\n",
    "        minute = 15\n",
    "    elif minute >= 22.5 and minute < 37.5:\n",
    "        minute = 30\n",
    "    elif minute >= 37.5 and minute < 52.5:\n",
    "        minute = 45\n",
    "    else:\n",
    "        minute = 0\n",
    "        \n",
    "    return dt.time(hour, minute, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The list of airports in our five main cities\n",
    "airports = pd.read_csv(\"../data/airport_names.csv\")\n",
    "\n",
    "# Split airports by city\n",
    "la = airports[airports.Description.str.contains(\"Los Angeles, CA\")]\n",
    "chi = airports[airports.Description.str.contains(\"Chicago, IL\")]\n",
    "bos = airports[airports.Description.str.contains(\"Boston, MA\")]\n",
    "pho = airports[airports.Description.str.contains(\"Phoenix, AZ\")]\n",
    "den = airports[airports.Description.str.contains(\"Denver, CO\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load weather data\n",
    "lat_lon = pd.read_csv(\"../data/weather/city_attributes.csv\")\n",
    "humidity = pd.read_csv(\"../data/weather/humidity.csv\")\n",
    "pressure = pd.read_csv(\"../data/weather/pressure.csv\")\n",
    "temp = pd.read_csv(\"../data/weather/temperature.csv\")\n",
    "desc = pd.read_csv(\"../data/weather/weather_description.csv\")\n",
    "wind_dir = pd.read_csv(\"../data/weather/wind_direction.csv\")\n",
    "wind_spe = pd.read_csv(\"../data/weather/wind_speed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Because each of the weather tables have the city names for each column, we need\n",
    "### to rename the columns to reflect the table that they come from.\n",
    "humidity = humidity[[\"datetime\",\"Los Angeles\", \"Chicago\", \"Boston\", \"Phoenix\", \"Denver\"]]\n",
    "humidity.columns = (\"datetimeh\",\"LA_h\",\"CHI_h\",\"BOS_h\",\"PHO_h\",\"DEN_h\")\n",
    "pressure = pressure[[\"datetime\",\"Los Angeles\", \"Chicago\", \"Boston\", \"Phoenix\", \"Denver\"]]\n",
    "pressure.columns = (\"datetimep\",\"LA_p\",\"CHI_p\",\"BOS_p\",\"PHO_p\",\"DEN_p\")\n",
    "temp = temp[[\"datetime\",\"Los Angeles\", \"Chicago\", \"Boston\", \"Phoenix\", \"Denver\"]]\n",
    "temp.columns = (\"datetimet\",\"LA_t\",\"CHI_t\",\"BOS_t\",\"PHO_t\",\"DEN_t\")\n",
    "desc = desc[[\"datetime\",\"Los Angeles\", \"Chicago\", \"Boston\", \"Phoenix\", \"Denver\"]]\n",
    "desc.columns = (\"datetimed\",\"LA_d\",\"CHI_d\",\"BOS_d\",\"PHO_d\",\"DEN_d\")\n",
    "wind_dir = wind_dir[[\"datetime\",\"Los Angeles\", \"Chicago\", \"Boston\", \"Phoenix\", \"Denver\"]]\n",
    "wind_dir.columns = (\"datetimewd\",\"LA_wd\",\"CHI_wd\",\"BOS_wd\",\"PHO_wd\",\"DEN_wd\")\n",
    "wind_spe = wind_spe[[\"datetime\",\"Los Angeles\", \"Chicago\", \"Boston\", \"Phoenix\", \"Denver\"]]\n",
    "wind_spe.columns = (\"datetimews\",\"LA_ws\",\"CHI_ws\",\"BOS_ws\",\"PHO_ws\",\"DEN_ws\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert datetime column to datetime object\n",
    "humidity.datetimeh = pd.to_datetime(humidity.datetimeh, format=\"%Y-%m-%d %H:%M:%S\")\n",
    "pressure.datetimep = pd.to_datetime(pressure.datetimep, format=\"%Y-%m-%d %H:%M:%S\")\n",
    "temp.datetimet = pd.to_datetime(temp.datetimet, format=\"%Y-%m-%d %H:%M:%S\")\n",
    "desc.datetimed = pd.to_datetime(desc.datetimed, format=\"%Y-%m-%d %H:%M:%S\")\n",
    "wind_dir.datetimewd = pd.to_datetime(wind_dir.datetimewd, format=\"%Y-%m-%d %H:%M:%S\")\n",
    "wind_spe.datetimews = pd.to_datetime(wind_spe.datetimews, format=\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in flights from August 2017\n",
    "flights = pd.read_csv(\"../data/flights2.csv\", dtype={'CRS_DEP_TIME':str})\n",
    "\n",
    "# Keep select columns\n",
    "flights = flights[['FL_DATE','OP_CARRIER_AIRLINE_ID','OP_CARRIER_FL_NUM','ORIGIN','DEST','CRS_DEP_TIME','DEP_DELAY_NEW','CRS_ELAPSED_TIME']]\n",
    "flights.columns = ('date','airline_id','flight_id','origin','dest','dep_time','delay','flight_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>airline_id</th>\n",
       "      <th>flight_id</th>\n",
       "      <th>origin</th>\n",
       "      <th>dest</th>\n",
       "      <th>dep_time</th>\n",
       "      <th>delay</th>\n",
       "      <th>flight_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>19805</td>\n",
       "      <td>1150</td>\n",
       "      <td>DFW</td>\n",
       "      <td>LGA</td>\n",
       "      <td>0635</td>\n",
       "      <td>0.0</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>19805</td>\n",
       "      <td>1152</td>\n",
       "      <td>DFW</td>\n",
       "      <td>JAC</td>\n",
       "      <td>1830</td>\n",
       "      <td>0.0</td>\n",
       "      <td>168.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>19805</td>\n",
       "      <td>1153</td>\n",
       "      <td>CLT</td>\n",
       "      <td>STT</td>\n",
       "      <td>1150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>233.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>19805</td>\n",
       "      <td>1153</td>\n",
       "      <td>JFK</td>\n",
       "      <td>CLT</td>\n",
       "      <td>0815</td>\n",
       "      <td>54.0</td>\n",
       "      <td>126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>19805</td>\n",
       "      <td>1155</td>\n",
       "      <td>LAX</td>\n",
       "      <td>LAS</td>\n",
       "      <td>1400</td>\n",
       "      <td>11.0</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  airline_id  flight_id origin dest dep_time  delay  flight_time\n",
       "0  2017-08-01       19805       1150    DFW  LGA     0635    0.0        206.0\n",
       "1  2017-08-01       19805       1152    DFW  JAC     1830    0.0        168.0\n",
       "2  2017-08-01       19805       1153    CLT  STT     1150    0.0        233.0\n",
       "3  2017-08-01       19805       1153    JFK  CLT     0815   54.0        126.0\n",
       "4  2017-08-01       19805       1155    LAX  LAS     1400   11.0         83.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add three columns for date\n",
    "flights['year'] = flights.date.str[:4]\n",
    "flights['month'] = flights.date.str[5:7]\n",
    "flights['day'] = flights.date.str[8:]\n",
    "flights.drop(columns=['date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Denver flights dataframe\n",
    "flights_den = flights.merge(den, left_on=\"origin\", right_on=\"Code\")\n",
    "for idx,row in flights_den.iterrows():\n",
    "    # Use round_date to create datetime object for the time of the flight\n",
    "    # This will help us match the weather info to the flight info\n",
    "    flights_den.at[idx, 'time'] = round_date(row.year, row.month, row.day, row.dep_time)\n",
    "    # Convert delay to a binary target. If the delay time > 0, \n",
    "    # then the flight was delayed.\n",
    "    if row.delay > 0:\n",
    "        flights_den.at[idx, 'delay'] = 1\n",
    "\n",
    "# Merge new dataframe with matching weather data\n",
    "flights_den = flights_den.merge(\n",
    "    humidity[['datetimeh','DEN_h']], left_on='time', right_on='datetimeh').merge(\n",
    "    pressure[['datetimep','DEN_p']], left_on='time', right_on='datetimep').merge(\n",
    "    temp[['datetimet','DEN_t']], left_on='time', right_on='datetimet').merge(\n",
    "    desc[['datetimed','DEN_d']], left_on='time', right_on='datetimed').merge(\n",
    "    wind_dir[['datetimewd','DEN_wd']], left_on='time', right_on='datetimewd').merge(\n",
    "    wind_spe[['datetimews','DEN_ws']], left_on='time', right_on='datetimews')\n",
    "\n",
    "# Drop unneeded columns\n",
    "flights_den.drop(columns=['Code','Description','datetimeh','datetimep','datetimet','datetimed','datetimewd','datetimews','time'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Los Angeles flights dataframe\n",
    "flights_la = flights.merge(la, left_on=\"origin\", right_on=\"Code\")\n",
    "for idx,row in flights_la.iterrows():\n",
    "    # Use round_date to create datetime object for the time of the flight\n",
    "    # This will help us match the weather info to the flight info\n",
    "    flights_la.at[idx, 'time'] = round_date(row.year, row.month, row.day, row.dep_time)\n",
    "    # Convert delay to a binary target. If the delay time > 0, \n",
    "    # then the flight was delayed.\n",
    "    if row.delay > 0:\n",
    "        flights_la.at[idx, 'delay'] = 1\n",
    "    \n",
    "# Merge new dataframe with matching weather data\n",
    "flights_la = flights_la.merge(\n",
    "    humidity[['datetimeh','LA_h']], left_on='time', right_on='datetimeh').merge(\n",
    "    pressure[['datetimep','LA_p']], left_on='time', right_on='datetimep').merge(\n",
    "    temp[['datetimet','LA_t']], left_on='time', right_on='datetimet').merge(\n",
    "    desc[['datetimed','LA_d']], left_on='time', right_on='datetimed').merge(\n",
    "    wind_dir[['datetimewd','LA_wd']], left_on='time', right_on='datetimewd').merge(\n",
    "    wind_spe[['datetimews','LA_ws']], left_on='time', right_on='datetimews')\n",
    "\n",
    "# Drop unneeded columns\n",
    "flights_la.drop(columns=['Code','Description','datetimeh','datetimep','datetimet','datetimed','datetimewd','datetimews','time'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Boston flights dataframe\n",
    "flights_bos = flights.merge(bos, left_on=\"origin\", right_on=\"Code\")\n",
    "for idx,row in flights_bos.iterrows():\n",
    "    # Use round_date to create datetime object for the time of the flight\n",
    "    # This will help us match the weather info to the flight info\n",
    "    flights_bos.at[idx, 'time'] = round_date(row.year, row.month, row.day, row.dep_time)\n",
    "    # Convert delay to a binary target. If the delay time > 0, \n",
    "    # then the flight was delayed.\n",
    "    if row.delay > 0:\n",
    "        flights_bos.at[idx, 'delay'] = 1\n",
    "    \n",
    "# Merge new dataframe with matching weather data\n",
    "flights_bos = flights_bos.merge(\n",
    "    humidity[['datetimeh','BOS_h']], left_on='time', right_on='datetimeh').merge(\n",
    "    pressure[['datetimep','BOS_p']], left_on='time', right_on='datetimep').merge(\n",
    "    temp[['datetimet','BOS_t']], left_on='time', right_on='datetimet').merge(\n",
    "    desc[['datetimed','BOS_d']], left_on='time', right_on='datetimed').merge(\n",
    "    wind_dir[['datetimewd','BOS_wd']], left_on='time', right_on='datetimewd').merge(\n",
    "    wind_spe[['datetimews','BOS_ws']], left_on='time', right_on='datetimews')\n",
    "\n",
    "# Drop unneeded columns\n",
    "flights_bos.drop(columns=['Code','Description','datetimeh','datetimep','datetimet','datetimed','datetimewd','datetimews','time'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Chicago flights dataframe\n",
    "flights_chi = flights.merge(chi, left_on=\"origin\", right_on=\"Code\")\n",
    "for idx,row in flights_chi.iterrows():\n",
    "    # Use round_date to create datetime object for the time of the flight\n",
    "    # This will help us match the weather info to the flight info\n",
    "    flights_chi.at[idx, 'time'] = round_date(row.year, row.month, row.day, row.dep_time)\n",
    "    # Convert delay to a binary target. If the delay time > 0, \n",
    "    # then the flight was delayed.\n",
    "    if row.delay > 0:\n",
    "        flights_chi.at[idx, 'delay'] = 1\n",
    "    \n",
    "# Merge new dataframe with matching weather data\n",
    "flights_chi = flights_chi.merge(\n",
    "    humidity[['datetimeh','CHI_h']], left_on='time', right_on='datetimeh').merge(\n",
    "    pressure[['datetimep','CHI_p']], left_on='time', right_on='datetimep').merge(\n",
    "    temp[['datetimet','CHI_t']], left_on='time', right_on='datetimet').merge(\n",
    "    desc[['datetimed','CHI_d']], left_on='time', right_on='datetimed').merge(\n",
    "    wind_dir[['datetimewd','CHI_wd']], left_on='time', right_on='datetimewd').merge(\n",
    "    wind_spe[['datetimews','CHI_ws']], left_on='time', right_on='datetimews')\n",
    "\n",
    "# Drop unneeded columns\n",
    "flights_chi.drop(columns=['Code','Description','datetimeh','datetimep','datetimet','datetimed','datetimewd','datetimews','time'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Phoenix flights dataframe\n",
    "flights_pho = flights.merge(pho, left_on=\"origin\", right_on=\"Code\")\n",
    "for idx,row in flights_pho.iterrows():\n",
    "    # Use round_date to create datetime object for the time of the flight\n",
    "    # This will help us match the weather info to the flight info\n",
    "    flights_pho.at[idx, 'time'] = round_date(row.year, row.month, row.day, row.dep_time)\n",
    "    # Convert delay to a binary target. If the delay time > 0, \n",
    "    # then the flight was delayed.\n",
    "    if row.delay > 0:\n",
    "        flights_pho.at[idx, 'delay'] = 1\n",
    "    \n",
    "# Merge new dataframe with matching weather data\n",
    "flights_pho = flights_pho.merge(\n",
    "    humidity[['datetimeh','PHO_h']], left_on='time', right_on='datetimeh').merge(\n",
    "    pressure[['datetimep','PHO_p']], left_on='time', right_on='datetimep').merge(\n",
    "    temp[['datetimet','PHO_t']], left_on='time', right_on='datetimet').merge(\n",
    "    desc[['datetimed','PHO_d']], left_on='time', right_on='datetimed').merge(\n",
    "    wind_dir[['datetimewd','PHO_wd']], left_on='time', right_on='datetimewd').merge(\n",
    "    wind_spe[['datetimews','PHO_ws']], left_on='time', right_on='datetimews')\n",
    "\n",
    "# Drop unneeded columns\n",
    "flights_pho.drop(columns=['Code','Description','datetimeh','datetimep','datetimet','datetimed','datetimewd','datetimews','time'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to facilitate concatenating the dataframes together\n",
    "flights_den.columns = ['airline_id','flight_id', 'origin', 'dest', 'dep_time','delay', 'flight_time','year','month','day', 'h', 'p','t', 'd', 'wd', 'ws']\n",
    "flights_la.columns = ['airline_id', 'flight_id', 'origin', 'dest', 'dep_time','delay', 'flight_time','year','month','day', 'h', 'p','t', 'd', 'wd', 'ws']\n",
    "flights_bos.columns = ['airline_id', 'flight_id', 'origin', 'dest', 'dep_time','delay', 'flight_time','year','month','day', 'h', 'p','t', 'd', 'wd', 'ws']\n",
    "flights_chi.columns = ['airline_id', 'flight_id', 'origin', 'dest', 'dep_time','delay', 'flight_time','year','month','day', 'h', 'p','t', 'd', 'wd', 'ws']\n",
    "flights_pho.columns = ['airline_id', 'flight_id', 'origin', 'dest', 'dep_time','delay', 'flight_time','year','month','day', 'h', 'p','t', 'd', 'wd', 'ws']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate dataframes\n",
    "all_flights = flights_den.append(\n",
    "    flights_la, ignore_index=True).append(\n",
    "    flights_bos, ignore_index=True).append(\n",
    "    flights_chi, ignore_index=True).append(\n",
    "    flights_pho, ignore_index=True)\n",
    "# Rename target variable (delay) to y\n",
    "all_flights = all_flights.rename(columns={'delay':'y'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Convert AirlineID to string, this will help when we create dummies\n",
    "### since AirlineID is a categorical variable\n",
    "all_flights.airline_id = all_flights.airline_id.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use round_quarter_hour to create time object for the departure time\n",
    "### If we fail to do this, we end up adding ~1400 dummy variables. To reduce\n",
    "### this number, we round each flight time to the nearest quarter hour\n",
    "for idx, row in all_flights.iterrows():\n",
    "    all_flights.at[idx,'dep_time_dt'] = round_quarter_hour(row.dep_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some values in our target variable (delay) are null. If the delay is\n",
    "### null, we are assuming there was no delay\n",
    "all_flights = all_flights.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target variable dataframe\n",
    "all_flights_y = all_flights['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create numpy arrays of training parameters and target parameter\n",
    "y = all_flights_y.to_numpy()\n",
    "x = all_flights.drop(columns=['y','dep_time', 'flight_id', 'year', 'month', 'day'])\n",
    "# Create dummy variables\n",
    "x = pd.get_dummies(x).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and testing data\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed: 11.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(), n_iter=50,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'criterion': ['gini', 'entropy'],\n",
       "                                        'max_depth': [None, 10, 50, 100, 150],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'n_estimators': [10, 20, 30, 40, 50, 60,\n",
       "                                                         70, 80, 90, 100]},\n",
       "                   verbose=4)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Use RandomizedSearchCV to discover the best set of parameters to\n",
    "### use while training the model\n",
    "rf = RandomForestClassifier()\n",
    "random_grid = {\n",
    "    'n_estimators': [x for x in range(10,101,10)],\n",
    "    'criterion': ['gini','entropy'],\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'min_samples_leaf': [1,2,4],\n",
    "    'bootstrap': [True, False],\n",
    "    'max_depth': [None, 10, 50, 100, 150]\n",
    "}\n",
    "\n",
    "rf_grid = RandomizedSearchCV(estimator=rf, param_distributions=random_grid, n_iter=50, cv=3, verbose=4, n_jobs=-1)\n",
    "\n",
    "rf_grid.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameters\n",
    "best = rf_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 70,\n",
       " 'min_samples_leaf': 4,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 150,\n",
       " 'criterion': 'gini',\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model based on best parameters\n",
    "rf = RandomForestClassifier(n_estimators=best['n_estimators'], \n",
    "                            max_depth=best['max_depth'],\n",
    "                            criterion=best['criterion'], \n",
    "                            min_samples_leaf=best['min_samples_leaf'],\n",
    "                            max_features=best['max_features'],\n",
    "                            bootstrap=best['bootstrap'],\n",
    "                           random_state=47906)\n",
    "rf.fit(train_x, train_y)\n",
    "\n",
    "# Get predictions and probabilities\n",
    "pred_rf = rf.predict(test_x)\n",
    "pred_prob_rf = rf.predict_proba(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for gini forest with 70 trees and a max depth of 150: 69.24%\n",
      "\n",
      "Probabilities: [0.65620065 0.34379935] -----> Actual: 1.0\n",
      "Probabilities: [0.42668702 0.57331298] -----> Actual: 1.0\n",
      "Probabilities: [0.62439403 0.37560597] -----> Actual: 1.0\n",
      "Probabilities: [0.77071774 0.22928226] -----> Actual: 0.0\n",
      "Probabilities: [0.68565656 0.31434344] -----> Actual: 0.0\n",
      "Probabilities: [0.63994167 0.36005833] -----> Actual: 0.0\n",
      "Probabilities: [0.53170801 0.46829199] -----> Actual: 0.0\n",
      "Probabilities: [0.50491681 0.49508319] -----> Actual: 0.0\n",
      "Probabilities: [0.44902036 0.55097964] -----> Actual: 1.0\n",
      "Probabilities: [0.78282686 0.21717314] -----> Actual: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Accuracy score\n",
    "acc_rf = accuracy_score(test_y, pred_rf)\n",
    "print(\"Accuracy for {} forest with {} trees and a max depth of {}: {}%\\n\".format(best['criterion'], best['n_estimators'], best['max_depth'], round(acc_rf*100,2)))\n",
    "for i in range(10):\n",
    "    print(\"Probabilities: {} -----> Actual: {}\".format(pred_prob_rf[i], test_y[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for NN model: 65.88%\n"
     ]
    }
   ],
   "source": [
    "nn = MLPClassifier(hidden_layer_sizes=(20,50,20), verbose=False, random_state=47906)\n",
    "nn.fit(train_x, train_y)\n",
    "\n",
    "pred_nn = nn.predict(test_x)\n",
    "\n",
    "acc = accuracy_score(test_y, pred_nn)\n",
    "print(\"Accuracy for NN model: {}%\".format(round(acc*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
